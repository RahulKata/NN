{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatterbot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRGSJmcyk1ru",
        "colab_type": "code",
        "outputId": "6067132a-b237-4930-d417-0d815d4b7a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6SgL05Ok3Fy",
        "colab_type": "code",
        "outputId": "025ca7f1-460a-4eb5-b2d5-55ccad04f5cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "import numpy\n",
        "import tflearn\n",
        "import tensorflow\n",
        "import random\n",
        "\n",
        "import json\n",
        "with open('/content/drive/My Drive/Colab Notebooks/intents.json') as file:\n",
        "    data = json.load(file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWwgX69YmQ0y",
        "colab_type": "code",
        "outputId": "c1dc5387-25ec-4be9-8daf-ab79e6cab7a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "words = []\n",
        "labels = []\n",
        "docs_x = []\n",
        "docs_y = []\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'context_set': '',\n",
              "   'patterns': ['Hi',\n",
              "    'How are you',\n",
              "    'Is anyone there?',\n",
              "    'Hello',\n",
              "    'Good day',\n",
              "    'Whats up'],\n",
              "   'responses': ['Hello!',\n",
              "    'Good to see you again!',\n",
              "    'Hi there, how can I help?'],\n",
              "   'tag': 'greeting'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['cya',\n",
              "    'See you later',\n",
              "    'Goodbye',\n",
              "    'I am Leaving',\n",
              "    'Have a Good day'],\n",
              "   'responses': ['Sad to see you go :(', 'Talk to you later', 'Goodbye!'],\n",
              "   'tag': 'goodbye'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['how old',\n",
              "    'how old is tim',\n",
              "    'what is your age',\n",
              "    'how old are you',\n",
              "    'age?'],\n",
              "   'responses': ['I am 18 years old!', '18 years young!'],\n",
              "   'tag': 'age'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['what is your name',\n",
              "    'what should I call you',\n",
              "    'whats your name?'],\n",
              "   'responses': ['You can call me Tim.',\n",
              "    \"I'm Tim!\",\n",
              "    \"I'm Tim aka Tech With Tim.\"],\n",
              "   'tag': 'name'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['Id like to buy something',\n",
              "    'whats on the menu',\n",
              "    'what do you reccommend?',\n",
              "    'could i get something to eat'],\n",
              "   'responses': ['We sell chocolate chip cookies for $2!',\n",
              "    'Cookies are on the menu!'],\n",
              "   'tag': 'shop'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['when are you guys open',\n",
              "    'what are your hours',\n",
              "    'hours of operation'],\n",
              "   'responses': ['We are open 7am-4pm Monday-Friday!'],\n",
              "   'tag': 'hours'}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjsoW1U8m80Y",
        "colab_type": "code",
        "outputId": "cec5c932-9710-4b37-86c3-c2be229e7c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        wrds = nltk.word_tokenize(pattern)\n",
        "        words.extend(wrds)\n",
        "        docs_x.append(wrds)\n",
        "        docs_y.append(intent[\"tag\"])\n",
        "        \n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])\n",
        "print(labels,'\\n',words,'\\n',docs_x,'\\n',docs_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['greeting', 'goodbye', 'age', 'name', 'shop', 'hours'] \n",
            " ['Hi', 'How', 'are', 'you', 'Is', 'anyone', 'there', '?', 'Hello', 'Good', 'day', 'Whats', 'up', 'cya', 'See', 'you', 'later', 'Goodbye', 'I', 'am', 'Leaving', 'Have', 'a', 'Good', 'day', 'how', 'old', 'how', 'old', 'is', 'tim', 'what', 'is', 'your', 'age', 'how', 'old', 'are', 'you', 'age', '?', 'what', 'is', 'your', 'name', 'what', 'should', 'I', 'call', 'you', 'whats', 'your', 'name', '?', 'Id', 'like', 'to', 'buy', 'something', 'whats', 'on', 'the', 'menu', 'what', 'do', 'you', 'reccommend', '?', 'could', 'i', 'get', 'something', 'to', 'eat', 'when', 'are', 'you', 'guys', 'open', 'what', 'are', 'your', 'hours', 'hours', 'of', 'operation'] \n",
            " [['Hi'], ['How', 'are', 'you'], ['Is', 'anyone', 'there', '?'], ['Hello'], ['Good', 'day'], ['Whats', 'up'], ['cya'], ['See', 'you', 'later'], ['Goodbye'], ['I', 'am', 'Leaving'], ['Have', 'a', 'Good', 'day'], ['how', 'old'], ['how', 'old', 'is', 'tim'], ['what', 'is', 'your', 'age'], ['how', 'old', 'are', 'you'], ['age', '?'], ['what', 'is', 'your', 'name'], ['what', 'should', 'I', 'call', 'you'], ['whats', 'your', 'name', '?'], ['Id', 'like', 'to', 'buy', 'something'], ['whats', 'on', 'the', 'menu'], ['what', 'do', 'you', 'reccommend', '?'], ['could', 'i', 'get', 'something', 'to', 'eat'], ['when', 'are', 'you', 'guys', 'open'], ['what', 'are', 'your', 'hours'], ['hours', 'of', 'operation']] \n",
            " ['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'age', 'age', 'age', 'age', 'age', 'name', 'name', 'name', 'shop', 'shop', 'shop', 'shop', 'hours', 'hours', 'hours']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pouyPWNWouR0",
        "colab_type": "code",
        "outputId": "e32d9938-c841-4c91-d95d-ae7fff11ed6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "labels = sorted(labels)\n",
        "\n",
        "print (len(docs_y), \"Sentences:\")\n",
        "print (len(labels), \"Intents:\", labels)\n",
        "print (len(words), \"Unique Stemmed Words\", words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26 Sentences:\n",
            "6 Intents: ['age', 'goodbye', 'greeting', 'hours', 'name', 'shop']\n",
            "46 Unique Stemmed Words ['a', 'ag', 'am', 'anyon', 'ar', 'buy', 'cal', 'could', 'cya', 'day', 'do', 'eat', 'get', 'good', 'goodby', 'guy', 'hav', 'hello', 'hi', 'hour', 'how', 'i', 'id', 'is', 'lat', 'leav', 'lik', 'menu', 'nam', 'of', 'old', 'on', 'op', 'reccommend', 'see', 'should', 'som', 'the', 'ther', 'tim', 'to', 'up', 'what', 'when', 'yo', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj_JH4bgC3Hm",
        "colab_type": "code",
        "outputId": "ad865cf2-5b09-4327-8093-42ab0f4aded0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "training = []\n",
        "output = []\n",
        "\n",
        "out_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "for x, doc in enumerate(docs_x):\n",
        "    bag = []\n",
        "\n",
        "    wrds = [stemmer.stem(w.lower()) for w in doc]\n",
        "\n",
        "    for w in words:\n",
        "        bag.append(1) if w in wrds else   bag.append(0)\n",
        "\n",
        "    output_row = out_empty[:]\n",
        "    output_row[labels.index(docs_y[x])] = 1\n",
        "\n",
        "    training.append(bag)\n",
        "    output.append(output_row)\n",
        "    \n",
        "training = numpy.array(training)\n",
        "output = numpy.array(output)\n",
        "print(f\"Training Data: {training} \\n Output: {output}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data: [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 1]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 1]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 0]] \n",
            " Output: [[0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 0 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1Y2W5otII6l",
        "colab_type": "code",
        "outputId": "ecfa3629-d7a9-4c03-a71c-97d73327e6c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "tensorflow.reset_default_graph()\n",
        "\n",
        "net = tflearn.input_data(shape=[None, len(training[0])])\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
        "net = tflearn.regression(net)\n",
        "\n",
        "model = tflearn.DNN(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kCEdwsFhC_J",
        "colab_type": "code",
        "outputId": "a1d5b8c8-601a-42da-9244-7a9b31e067e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
        "model.save(\"model.tflearn\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 3999  | total loss: \u001b[1m\u001b[32m0.41346\u001b[0m\u001b[0m | time: 0.021s\n",
            "| Adam | epoch: 1000 | loss: 0.41346 - acc: 0.9629 -- iter: 24/26\n",
            "Training Step: 4000  | total loss: \u001b[1m\u001b[32m0.38475\u001b[0m\u001b[0m | time: 0.031s\n",
            "| Adam | epoch: 1000 | loss: 0.38475 - acc: 0.9666 -- iter: 26/26\n",
            "--\n",
            "INFO:tensorflow:/content/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVlkA5GDhR-J",
        "colab_type": "code",
        "outputId": "8c50a50e-0585-41b4-886c-afa8605f81ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "def bag_of_words(s, words):\n",
        "    bag = [0 for _ in range(len(words))]\n",
        "\n",
        "    s_words = nltk.word_tokenize(s)\n",
        "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "\n",
        "    for se in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == se:\n",
        "                bag[i] = 1\n",
        "            \n",
        "    return numpy.array(bag)\n",
        "\n",
        "\n",
        "def chat():\n",
        "    print(\"Start talking with the bot (type quit to stop)!\")\n",
        "    while True:\n",
        "        inp = input(\"You: \")\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        results = model.predict([bag_of_words(inp, words)])\n",
        "        results_index = numpy.argmax(results)\n",
        "        tag = labels[results_index]\n",
        "\n",
        "        for tg in data[\"intents\"]:\n",
        "            if tg['tag'] == tag:\n",
        "                responses = tg['responses']\n",
        "\n",
        "        print(random.choice(responses))\n",
        "\n",
        "chat()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start talking with the bot (type quit to stop)!\n",
            "You: hi\n",
            "Hi there, how can I help?\n",
            "You: what's your name?\n",
            "I'm Tim!\n",
            "You: full name?\n",
            "You can call me Tim.\n",
            "You: no i wont\n",
            "Hi there, how can I help?\n",
            "You: f u\n",
            "Hello!\n",
            "You: what's the time now\n",
            "We are open 7am-4pm Monday-Friday!\n",
            "You: quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMGZJvDdlPru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}